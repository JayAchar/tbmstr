---
title: "Введение в регрессионное моделирование "
output: 
  learnr::tutorial:
    progressive: true
runtime: shiny_prerendered
description: "Практическое занятие по регрессионному моделированию "
---

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
library(dplyr)
library(ggplot2)
library(broom)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(
  exercise.completion = TRUE
)

# example data for linear regression
set.seed(12345)
slope <- 1.8
x <- runif(30, min = 8, max = 40)
y <- slope * x + runif(
  length(x),
  min = -20,
  max = 20
)
lm_data <- data.frame(
  x, y
)

lm_model <- lm(y ~ x, lm_data) |>
  broom::tidy()

slope_param <- lm_model$estimate[which(lm_model$term == "x")]
intercept_param <- lm_model$estimate[which(lm_model$term == "(Intercept)")]

# example data for logsitic regression
mat <- data.frame(
  diabetes = c(
    rep(TRUE, 2),
    rep(FALSE, 2)
  ),
  had_sae = c(
    rep(c(TRUE, FALSE), 2)
  ),
  count = c(152, 63, 281, 267)
)

lr_df <- mat[rep(sequence(nrow(mat)), mat[["count"]]), ]
lr_df$count <- NULL

lr_model <- glm(
  had_sae ~ diabetes, lr_df,
  family = binomial(link = "logit")
) |> broom::tidy(conf.int = TRUE, exponentiate = TRUE)
```
## Введение в регрессионное моделирование

В этом руководстве вы будете выполнять следующие задачи:
* Исследование оценочных значений параметров с помощью линейной регрессии,
* Составление прогнозов с использованием параметров модели,
* Подбор модели логистической регрессии и интерпретация результатов,
* Подбор многомерной модели логистической регрессии

## Линейная регрессия

### Понимание параметров

Когда мы ставим перед программой R задачу "подобрать" для нас регрессионную 
модель, она использует алгоритм для оценки линии наилучшего соответствия. 
Результат дает нам оценки параметров, которые можно использовать для 
обобщения этой линии. 

В ситуации, когда у нас есть одна объясняющая переменная, уравнение 
выглядит следующим образом: 

$$
Y \sim \beta_0 + X\beta_1
$$

Для модели, в которой вес является результатом, а рост является 
объясняющей переменной, уравнение будет выглядеть так:
$$
weight \sim \beta_0 + \beta_1 height 
$$

### Расчет параметров

Используя приведенный ниже график, определите пересечение точек и наклон 
наиболее подходящей линии регрессии.

```{r lm-shiny-ui }
sliderInput("intercept", "расчет точек пересечения:",
  min = -50,
  max = 50,
  value = 1
)
sliderInput("slope", "расчет наклона функции:",
  min = 1,
  max = 5,
  value = 1,
  step = 0.1
)
plotOutput("distPlot")
```
```{r lm-shiny-server, context = "server" }
output$distPlot <- renderPlot({
  ggplot(
    lm_data,
    aes(x = x, y = y)
  ) +
    geom_point() +
    geom_abline(
      intercept = input$intercept,
      slope = input$slope,
      color = "red"
    ) +
    labs(
      x = " Пояснительная",
      y = "Результат"
    ) +
    theme_light()
})
```
### Расчеты параметров

Модель была подобрана с помощью функции `lm` для линейной регрессии:

```{r lm-code, echo = TRUE, eval = FALSE}
lm(
  y ~ x,
  data = lm_data
) |>
  broom::tidy()
```
Ниже приведен результат кода. Ответьте на следующие вопросы.

```{r lm-parameter-estimates }
lm_model
```

```{r quiz-lm-parameters }
quiz(
  caption = NULL,
  question(
    "Можно ли выбрать правильный расчет параметра наклона функции из
    приведенного выше результата модели?",
    answer(round(slope_param, 1),
      correct = TRUE
    ),
    answer(1.2),
    answer(2.8),
    answer(0.6),
    random_answer_order = TRUE,
    allow_retry = TRUE
  ),
  question(
    " Можете ли вы выбрать правильный расчет параметра пересечения точек?",
    answer(round(intercept_param, 3),
      correct = TRUE
    ),
    answer(3.248),
    answer(-2.773),
    answer(1.285),
    random_answer_order = TRUE,
    allow_retry = TRUE
  )
)
```
## Прогнозирование

Мы можем использовать расчеты параметров, предоставленные функцией 
`lm`, для прогнозирования результата на основе объясняющей(их) переменной(ых).

В нашем предыдущем примере результат был следующим:

```{r prediction-model }
lm_model
```
Используйте расчеты параметров для вычисления результата, когда 
объясняющая переменная равна 35. **Округлите свой ответ до 2 знаков после запятой.**

```{r predict-outcome, exercise = TRUE, exercise.eval = TRUE }

```
```{r predict-outcome-check }
result <- round(slope_param * 35 + intercept_param, 2)

grade_this({
  if (.result == result) {
    pass("Выполнено успешно!")
  }
  fail("Извините - это неправильно, попробуйте использовать подсказку.")
})
```
```{r predict-outcome-hint }
slope_param * 35 + intercept_param
```
## Логистическая регрессия

### Данные для примера

Для изучения логистической регрессии мы будем использовать некоторые 
примеры данных. Результатом переменной будет факт наличия у участника СНЯ 
во время лечения (had_sae), а переменной воздействия будет бинарная 
переменная, указывающая на наличие или отсутствие у участника диабета.

```{r lr-example-data }
shuffled <- lr_df[sample(1:nrow(lr_df)), ]
knitr::kable(head(shuffled, 10), row.names = FALSE)
```
### Логарифмическое преобразование

Прежде чем мы подберем нашу модель логистической регрессии, давайте попробуем 
сделать логарифмическое преобразование и возведение в степень, чтобы лучше 
понять, как это работает.

```{r log-transformation-setup }
log_values <- c(0.1, 0.5, 1, 2, 3, 4, 5, 10, 20, 50)
exp_values <- log(log_values)
```
В приведенном ниже блоке кода проведите логарифмическое преобразование 
следующих значений - `r log_values` 

```{r log-transformation, exercise = TRUE, exercise.eval = TRUE }

```
```{r log-transformation-hint }
log(c(0.1, 0.5, 1, 2, 3, 4, 5, 10, 20, 50))
```
```{r log-transformation-check }
result <- log(log_values)

grade_this({
  if (all(.result == result)) {
    pass("Выполнено успешно!")
  }
  fail("Извините, попробуйте использовать подсказку!")
})
```
### Графическое изображение - логарифмическое преобразование

Приведенный ниже график показывает, как изменяется значение после 
логарифмического преобразования. По мере того, как исходные значения 
увеличиваются, логарифмически преобразованные значения увеличиваются, 
но не значительно.
 
Логарифмическое преобразование значений меньше 1 приводит к отрицательным 
значениям. Отрицательные значения не были включены, так как логарифмическое 
преобразование отрицательных значений невозможно.

Обратите внимание, что `log(1)` равен нулю.

```{r log-transformation-plot }
ggplot(
  data.frame(
    x = log_values,
    y = log(log_values)
  ),
  aes(x = x, y = y)
) +
  geom_point() +
  theme_light() +
  labs(
    x = " Исходные значения",
    y = "Логарифмически преобразованные значения "
  )
```

### Возведение в степень 

Поскольку у большинства людей нет интуитивного понимания того, как 
интерпретировать логарифмически преобразованные значения, перед их 
представлением мы должны преобразовать эти значения обратно в обычные числа.
**Как нам конвертировать логарифмически преобразованные значения обратно в 
их исходные значения?**

Мы будем использовать функцию `exp` для возведения значений в степень:

```{r exponentiate-example, echo = TRUE}
exp_values
exp(exp_values)
```
Обратите внимание, как возвращенные значения вернулись к исходному вектору.

### Интерпретация

Далее мы применим модель логистической регрессии к данным примера. 
Переменной результата является `had_sae`, а единственной объясняющей 
переменной является `диабет`. Обе переменные - бинарные - TRUE или FALSE.

Обратите внимание, что мы использовали функцию `tidy` из пакета `broom`. 
для улучшения формата результата кода, для возведения результатов в степень, 
чтобы мы видели отношение шансов, а не логарифмическое отношение шансов, а 
также для добавления 95% доверительных интервалов. После просмотра 
результатов попробуйте ответить на вопросы.

```{r example-logistic-regression, echo = TRUE }
glm(
  had_sae ~ diabetes,
  data = lr_df,
  family = binomial(link = "logit")
) |> broom::tidy(
  exponentiate = TRUE,
  conf.int = TRUE
)
```

```{r quiz-logistic-regression }
diabetes_param <- round(lr_model$estimate[which(
  lr_model$term == "diabetesTRUE"
)], 4)
quiz(
  caption = NULL,
  question(
    glue::glue("Отношение шансов для диабета составляет {diabetes_param}.
               Как вы интерпретируете это значение?"),
    answer(glue::glue("По сравнению с участниками без диабета, участники
                      с диабетом имели в {diabetes_param} раз больше
                      шансов испытать СНЯ во время лечения"),
      correct = TRUE
    ),
    answer("Мы должны возвести значение в степень, прежде чем
           интерпретировать его как отношение шансов"),
    answer("Мы можем логарифмически преобразовать отношение шансов для
           диабета, чтобы оценить шансы участника без диабета, страдающего от
           СНЯ"),
    answer("95% доверительный интервал должен включать 1 чтобы результат
           был действительным."),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```
## Многомерная логистическая регрессия

Используя другой пример набора данных, мы подберем многомерную логистическую 
регрессионную модель. Это означает, что у нас будет более одной объясняющей 
переменной (age-group and baseline smear status), но при этом только один 
результат (treatment failure).

```{r mv-lr-setup }
mat <- data.frame(
  age_group = c(
    rep("5-9y", 4),
    rep("10-19y", 4),
    rep("20-39y", 4),
    rep("40y+", 4)
  ),
  smear_positive = c(
    rep(c(FALSE, FALSE, TRUE, TRUE), 4)
  ),
  tx_failure = c(
    rep(c(FALSE, TRUE), 8)
  ),
  count = c(
    77, 16, 79, 30,
    50, 22, 69, 77,
    85, 123, 40, 176,
    55, 120, 25, 258
  )
)

mv_lr_df <- mat[rep(sequence(nrow(mat)), mat[["count"]]), ]
mv_lr_df$count <- NULL

mv_lr_model <- glm(
  tx_failure ~ age_group + smear_positive,
  data = mv_lr_df,
  family = binomial(link = "logit")
) |> broom::tidy(
  exponentiate = TRUE,
  conf.int = TRUE
)
```
Вот первые 10 строк примера набора данных - обратите внимание, что переменная 
`age_group` имеет более 2 уровней:

```{r mv-lr-example }
shuffled <- mv_lr_df[sample(1:nrow(mv_lr_df)), ]
knitr::kable(head(shuffled, 10), row.names = FALSE)
```
Мы заполняем следующую модель. Обратите внимание, как мы добавляем 2 
объясняющие переменные в правую часть уравнения. Они объединяются с помощью 
знака `+`. Просмотрите результаты, приведенные ниже, и ответьте на 
следующие вопросы.

```{r mv-lr, echo = TRUE }
glm(
  tx_failure ~ age_group + smear_positive,
  data = mv_lr_df,
  family = binomial(link = "logit")
) |> broom::tidy(
  exponentiate = TRUE,
  conf.int = TRUE
)
```

```{r quiz-mv-lr }
smear_positive_odds <- round(mv_lr_model$estimate[which(
  mv_lr_model$term == "smear_positiveTRUE"
)], 2)

quiz(
  caption = NULL,
  question(
    "Как мы должны интерпретировать отношение шансов для участников с
    положительными результатами мазка (`smear_positive`)
    (select all correct answers)",
    answer(glue::glue("После корректировки на возрастную группу участники с
                      положительными результатами мазка по сравнению с
                      участниками с отрицательным мазком имеют в
                      {smear_positive_odds} раз больше шансов на
                      безуспешное лечение"),
      correct = TRUE
    ),
    answer("95% доверительный интервал для исходного статуса мазка не
            включает 1, поэтому нет достаточных доказательств в пользу
            наличия связи"),
    answer("Значение величины p очень малое - <0,001 - что означает наличие
           убедительных доказательств наличия связи после корректировки на
           возрастную группу",
      correct = TRUE
    ),
    answer("Оценка отношения шансов не скорректирована на возрастную группу"),
    random_answer_order = TRUE,
    allow_retry = TRUE
  ),
  question(
    "Почему для переменной `возрастная_группа` (`age_group`) показаны 3
    разные оценки переменной отношения шансов?",
    answer("Каждый уровень объясняющей переменной сравнивается с `базовым`
           уровнем. Существует 4 возрастные группы, поэтому есть сообщения о
           3 уровнях.", correct = TRUE),
    answer("Функция `glm` рассчитала, что отношения шансов отличаются в
           этих группах, поэтому мы должны сообщить о них отдельно"),
    answer("Это не понятно - есть 4 возрастные группы, поэтому должно
                  быть 4 отношения шансов"),
    random_answer_order = TRUE,
    allow_retry = TRUE
  )
)
```
## Вывод


В этом руководстве мы изучили регрессионное моделирование и, в частности, 
рассмотрели пример многомерной логистической регрессии. 

В другом занятии мы определим эффект от увеличения числа 
объясняющих переменных, включенных в модель логистической регрессии.
